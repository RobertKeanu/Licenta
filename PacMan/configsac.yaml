behaviors:
  Agent Control:
    trainer_type: sac
    hyperparameters:
      learning_rate: 0.00005  
      learning_rate_schedule: linear 
      batch_size: 128  
      buffer_size: 1000000  
      buffer_init_steps: 90000  
      tau: 0.005
      steps_per_update: 100.0  
      save_replay_buffer: true  
      init_entcoef: 0.3
      reward_signal_steps_per_update: 20.0 
    network_settings:
      normalize: false 
      hidden_units: 64
      num_layers: 3
      vis_encode_type: simple  
    reward_signals:
      extrinsic:
        gamma: 0.995
        strength: 1.0
      gail:
        strength: 0.5
        demo_path: Demos/DemoPacmanComp4.demo
    behavioral_cloning:
      strength: 0.6
      demo_path: Demos/DemoPacmanComp4.demo
    max_steps: 1000000
    time_horizon: 64
    summary_freq: 30000
    keep_checkpoints: 3  
    threaded: true  
