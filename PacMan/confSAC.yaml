behaviors:
  Agent Control:
    trainer_type: sac
    hyperparameters:
      learning_rate: 0.000000001  
      learning_rate_schedule: constant 
      batch_size: 256  
      buffer_size: 2000000  
      buffer_init_steps: 90000  
      tau: 0.005
      steps_per_update: 50.0  
      save_replay_buffer: true  
      init_entcoef: 0.3
      reward_signal_steps_per_update: 20.0 
    network_settings:
      normalize: false 
      hidden_units: 1024
      num_layers: 3
      vis_encode_type: simple  
    reward_signals:
      extrinsic:
        gamma: 0.995
        strength: 1.0
    max_steps: 2400000
    time_horizon: 64
    summary_freq: 30000
    keep_checkpoints: 3  
    threaded: true  
